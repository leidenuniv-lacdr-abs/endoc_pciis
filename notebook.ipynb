{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Imports\n",
    "#######################################\n",
    "\n",
    "# Pandas for data wrangling and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Altair for visualization\n",
    "import altair as alt\n",
    "\n",
    "# Access to files & folders\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# A function for extracting a DataFrame from mzML (XML with raw data)\n",
    "from src.mzml_parser import df_from_mzml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript // disable scolling in notebook\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Settings\n",
    "#######################################\n",
    "# for resampling of signal data to \n",
    "# make it consistent and comparable\n",
    "\n",
    "# Resample time dimension\n",
    "scans_per_second = 8\n",
    "\n",
    "# Savitzky-Golay filter\n",
    "window_length = 5 # window length (scipy.signal.savgol_filter)\n",
    "polyorder = 3     # polyorder (scipy.signal.savgol_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the targets to apply PCI_IS correction\n",
    "# by reading them in from a csv file\n",
    "targets = pd.read_csv(\n",
    "    'targets.csv', sep=\"\\t\",\n",
    "    converters = {'precursor': str, 'product': str}\n",
    ")\n",
    "\n",
    "# Add column with unique transition information\n",
    "targets['transition'] = targets.apply(\n",
    "    lambda x: f\"{x['precursor']}_{x['product']}_{x['polarity']}\", axis=1\n",
    ")\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PCI_IS transition to use and correct with\n",
    "pciis = {'name': '2F_AEA_02','transition': '350.3_269.2_pos'}\n",
    "\n",
    "pciis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw signal data from mzml files\n",
    "mzML_files = glob(os.path.join('mzML','*.mzML'))\n",
    "\n",
    "# Collect all individual DataFrames as a list\n",
    "mzML_dfs = [df_from_mzml(mzml_file, scans_per_second, window_length, polyorder) for mzml_file in mzML_files]\n",
    "\n",
    "# And combine them into a single DataFrame\n",
    "signal_df = pd.concat(mzML_dfs)\n",
    "\n",
    "signal_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PCI_IS signal\n",
    "pciis_filter = signal_df['transition'] == pciis['transition']\n",
    "pciis_data = signal_df[pciis_filter][['file', 'rt','intensity']].copy()\n",
    "\n",
    "# Change the column name of the intensity to pciis and \n",
    "# set the index of the DataFrame to file/rt to be able \n",
    "# to stitch the column to the target signal\n",
    "pciis_data.rename(columns={'intensity': 'pciis'}, inplace=True)\n",
    "pciis_data = pciis_data.set_index(['file', 'rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eeb2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine signal from all targets into a single DataFrame\n",
    "dfs = []\n",
    "for tIdx, target in targets.iterrows():\n",
    "    \n",
    "    # Extract target signal\n",
    "    target_filter = signal_df['transition'] == target['transition']\n",
    "    target_data = signal_df[target_filter].copy()\n",
    "    \n",
    "    # Keep index, in case we have multiple targets with the same transition\n",
    "    target_data['target'] = tIdx\n",
    "       \n",
    "    # Prepare index for join with pciis signal using file/rt\n",
    "    target_data = target_data.set_index(['file', 'rt'])    \n",
    "    \n",
    "    # Stitch the PCI_IS signal to the dataframe as a column\n",
    "    dfs.append(target_data.join(pciis_data['pciis']).reset_index())\n",
    "    \n",
    "# Combine the DataFrames again    \n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# Extract concentration information from filename\n",
    "df['concentration'] = df['file'].apply(\n",
    "    lambda x: x.split(\"_\")[-1].replace(\".mzML\",\"\")\n",
    ")\n",
    "\n",
    "# Extract sample information from filename\n",
    "df['sample'] = df['file'].apply(\n",
    "    lambda x: x.split(\"_\")[-2]\n",
    ")\n",
    "\n",
    "# Calculate ratio between intensity and pciis\n",
    "df['ratio'] = df['intensity']/df['pciis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f423bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import shift\n",
    "\n",
    "# The phase align code has been used from \n",
    "# GitHub: https://github.com/pearsonkyle/Signal-Alignment\n",
    "# Citation: http://iopscience.iop.org/article/10.3847/1538-3881/aaf1ae/meta\n",
    "from src.signal_alignment import phase_align\n",
    "\n",
    "# Define reference (ratio) signal to align to\n",
    "reference_file = os.path.join('mzML','inj043_PlDiv2_LOW.mzML')\n",
    "\n",
    "# Extract ratio by target/rt from the reference file\n",
    "reference__filter = df['file'] == reference_file\n",
    "reference_ratio = df[reference__filter][['target','rt','ratio']].copy()\n",
    "reference_ratio = reference_ratio.set_index(['target','rt'])\n",
    "\n",
    "# Change the column name\n",
    "reference_ratio.rename(columns={'ratio': 'ratio_reference'}, inplace=True)\n",
    "\n",
    "# Append a column with the ratio by rt from the reference file\n",
    "df_aligned = df.set_index(['target','rt']).join(reference_ratio).reset_index().dropna()\n",
    "\n",
    "# Apply alignement by target/file\n",
    "aligned_dfs = []\n",
    "for gIdx, df_grouped in df_aligned.groupby(['target','file']):\n",
    "                   \n",
    "    df_grouped['ratio_aligned'] = shift( # apply phase shift\n",
    "        df_grouped['ratio'], \n",
    "        float(phase_align( # calculate phase shift\n",
    "            df_grouped['ratio_reference'].values, df_grouped['ratio'].values, res=1\n",
    "        )), \n",
    "        mode='constant', \n",
    "        cval=0.0\n",
    "    )\n",
    "    \n",
    "    aligned_dfs.append(df_grouped)\n",
    "    \n",
    "# Merge them back together\n",
    "df_aligned = pd.concat(aligned_dfs, ignore_index=True)\n",
    "\n",
    "# Make all negative values = 0. Negative values could appear\n",
    "# due to the Savitzky-Golay filter that has been applied\n",
    "df_aligned['ratio_aligned'] = df_aligned['ratio_aligned'].clip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78411053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to determine the area of a peak\n",
    "# We do this with the help of the peak_widths function\n",
    "# from the scipy package, and the detect_peaks function\n",
    "# for the package detecta.\n",
    "from scipy.signal import peak_widths\n",
    "import warnings\n",
    "\n",
    "# Duarte, M. (2020) detecta: A Python module to detect events in data. \n",
    "# GitHub repository, https://github.com/demotu/detecta.\n",
    "from detecta import detect_peaks\n",
    "\n",
    "# Initialize an empty list to collect all peak DataFrames found with\n",
    "# the required meta-data such as apex, width, start, end, etc.\n",
    "peak_dfs = []\n",
    "for tIdx, df_target in df_aligned.groupby('target'):\n",
    "    \n",
    "    # Get target details\n",
    "    t = targets.loc[tIdx]\n",
    "    \n",
    "    for fIdx, df_target_file in df_target.groupby('file'):\n",
    "    \n",
    "        # By signal type (intensity or ratio)\n",
    "        for signal_type in ['intensity','ratio','ratio_aligned']:\n",
    "            peak_index = detect_peaks(\n",
    "                df_target_file[signal_type],\n",
    "                mph=0,\n",
    "                mpd=5,\n",
    "                threshold=0,\n",
    "                edge='both',\n",
    "                kpsh=True\n",
    "            )\n",
    "\n",
    "            # Suppress the warnings of the peak_width function\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                peak_width_index = peak_widths(\n",
    "                    df_target_file[signal_type],\n",
    "                    peak_index,\n",
    "                    rel_height=0.98\n",
    "                )\n",
    "\n",
    "            # Collect peak meta-data\n",
    "            peak_rt_apex = df_target_file.iloc[peak_index,]['rt']\n",
    "            peak_int_apex = df_target_file.iloc[peak_index,][signal_type]\n",
    "\n",
    "            peak_rt_start = df_target_file.iloc[peak_width_index[2],]['rt']\n",
    "            peak_int_start = df_target_file.iloc[peak_width_index[2],][signal_type]\n",
    "\n",
    "            peak_rt_end = df_target_file.iloc[peak_width_index[3],]['rt']\n",
    "            peak_int_end = df_target_file.iloc[peak_width_index[3],][signal_type]\n",
    "\n",
    "            peak_width = [ pw[0] - pw[1] for pw in zip(peak_rt_end,peak_rt_start) ]\n",
    "\n",
    "            peaks_df = pd.DataFrame({\n",
    "                'peak_rt_apex':peak_rt_apex.tolist(),\n",
    "                'peak_rt_start':peak_rt_start.tolist(),\n",
    "                'peak_rt_end':peak_rt_end.tolist(),\n",
    "                'peak_width':peak_width,\n",
    "            })\n",
    "\n",
    "            # Calculate the absolute error between the retention time found of the \n",
    "            # apex and the expected retention time as predefined in the targets file.\n",
    "            peaks_df['abs_rt_error'] = peaks_df['peak_rt_apex'].apply(\n",
    "                lambda x: abs(x - t.rt)\n",
    "            )\n",
    "\n",
    "            # We are only interested in the peak with the smallest retention time error.\n",
    "            peaks_df = peaks_df.nsmallest(1, 'abs_rt_error')\n",
    "            \n",
    "            # Keep track of where the peaks where found, in what \n",
    "            # sample, of what target, and based on what signal.\n",
    "            peaks_df['signal_type'] = signal_type\n",
    "            peaks_df['target'] = tIdx\n",
    "            peaks_df['file'] = fIdx            \n",
    "\n",
    "            # Calculate the peak area\n",
    "            peaks_df['area'] = peaks_df.apply(\n",
    "                lambda row:\n",
    "                    df_target_file[\n",
    "                        (df_target_file['rt'] >= row['peak_rt_start']) & \n",
    "                        (df_target_file['rt'] <= row['peak_rt_end'])\n",
    "                    ][signal_type].sum()\n",
    "                ,axis=1\n",
    "            )\n",
    "    \n",
    "            # Keep track of the number of scans used to determine the peak area\n",
    "            peaks_df['scans'] = peaks_df.apply(\n",
    "                lambda row:\n",
    "                    len(df_target_file[\n",
    "                        (df_target_file['rt'] >= row['peak_rt_start']) & \n",
    "                        (df_target_file['rt'] <= row['peak_rt_end'])\n",
    "                    ][signal_type])\n",
    "                ,axis=1\n",
    "            )    \n",
    "            \n",
    "            # And add it to the list to combine later\n",
    "            peak_dfs.append(peaks_df)\n",
    "               \n",
    "# Merge them back together\n",
    "df_peaks = pd.concat(peak_dfs, ignore_index=True)  \n",
    "\n",
    "# Add concentration\n",
    "df_peaks['concentration'] = df_peaks['file'].apply(\n",
    "    lambda x: x.split(\"_\")[-1].replace(\".mzML\",\"\")\n",
    ")\n",
    "\n",
    "# Add sample\n",
    "df_peaks['sample'] = df_peaks['file'].apply(\n",
    "    lambda x: x.split(\"_\")[-2]\n",
    ")\n",
    "\n",
    "# Save peaks as csv file\n",
    "df_peaks.to_csv('peaks_found.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783096f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plot_height = 180\n",
    "plot_width = 210\n",
    "rt_window = 12\n",
    "\n",
    "# Plot signals of all targets to visualize and compare the impact\n",
    "# of PCI_IS correction on the signal\n",
    "for tIdx, target in targets.iterrows():\n",
    "\n",
    "    # Get target details\n",
    "    t = targets.loc[tIdx]\n",
    "    \n",
    "    # Extract target signal\n",
    "    df_aligned_window = df_aligned[\n",
    "        (df_aligned['rt'] >= t.rt - rt_window/2) &\n",
    "        (df_aligned['rt'] <= t.rt + rt_window/2)\n",
    "    ].copy()   \n",
    "\n",
    "    plots = alt.vconcat()\n",
    "    \n",
    "    # Show the plots for each concentration ('LOW','MEDIUM','HIGH')\n",
    "    for concentration in df_aligned_window['concentration'].unique():\n",
    "        \n",
    "        # Data frame with peaks of target, grouped by concentration\n",
    "        df_concentration_peaks = df_peaks[\n",
    "            (df_peaks['target'] == tIdx) &\n",
    "            (df_peaks['concentration'] == concentration)\n",
    "        ]\n",
    "\n",
    "        # Data frame with signals of target, grouped by concentration\n",
    "        df_concentration_signal = df_aligned_window[\n",
    "            (df_aligned_window['target'] == tIdx) &\n",
    "            (df_aligned_window['concentration'] == concentration)\n",
    "        ]\n",
    "\n",
    "        # Original signal\n",
    "        intensity_plot = alt.Chart(df_concentration_signal).mark_line().encode(\n",
    "            x='rt', y='intensity', color='sample'\n",
    "        ).properties(\n",
    "            width=plot_width, height=plot_height, \n",
    "            title=f\"intensity ({concentration}) {t['name']}\"\n",
    "        )\n",
    "        \n",
    "        # Pciis signal\n",
    "        intensity_plot = intensity_plot + alt.Chart(df_concentration_signal).mark_line(\n",
    "            strokeWidth=0.5\n",
    "        ).encode(\n",
    "            x='rt', y='pciis', color='sample'\n",
    "        ).properties(\n",
    "            width=plot_width, height=plot_height\n",
    "        )        \n",
    "\n",
    "        # Add rt of target (red verticle line)\n",
    "        intensity_plot = intensity_plot + alt.Chart(\n",
    "            df_concentration_peaks[df_concentration_peaks['signal_type'] == 'intensity']).mark_rule(\n",
    "                color='red', strokeWidth=2\n",
    "            ).encode(\n",
    "                alt.X('mean(peak_rt_apex)',\n",
    "                  title='rt')        \n",
    "            )\n",
    "\n",
    "        # Add area window (start) of target (red verticle line)\n",
    "        intensity_plot = intensity_plot + alt.Chart(\n",
    "            df_concentration_peaks[df_concentration_peaks['signal_type'] == 'intensity']).mark_rule(\n",
    "                color='grey', strokeWidth=2\n",
    "            ).encode(\n",
    "                x='min(peak_rt_start)'\n",
    "            )\n",
    "\n",
    "        # Add area window (end) of target (red verticle line)\n",
    "        intensity_plot = intensity_plot + alt.Chart(\n",
    "            df_concentration_peaks[df_concentration_peaks['signal_type'] == 'intensity']).mark_rule(\n",
    "                color='grey', strokeWidth=2\n",
    "            ).encode(\n",
    "                x='min(peak_rt_end)'\n",
    "            )   \n",
    "\n",
    "        # Ratio\n",
    "        unaligned_plot = alt.Chart(df_concentration_signal).mark_line().encode(\n",
    "            x='rt', y='ratio', color='sample'\n",
    "        ).properties(\n",
    "            width=plot_width, height=plot_height, \n",
    "            title=f\"ratio ({concentration}) {t['name']}\"\n",
    "        )\n",
    "\n",
    "        # Add rt of target (red verticle line)\n",
    "        unaligned_plot = unaligned_plot + alt.Chart(\n",
    "            df_concentration_peaks[df_concentration_peaks['signal_type'] == 'ratio']).mark_rule(\n",
    "                color='red', strokeWidth=2\n",
    "            ).encode(\n",
    "                alt.X('mean(peak_rt_apex)',\n",
    "                  title='rt')        \n",
    "            )\n",
    "\n",
    "        # Add area window (start) of target (red verticle line)\n",
    "        unaligned_plot = unaligned_plot + alt.Chart(\n",
    "            df_concentration_peaks[df_concentration_peaks['signal_type'] == 'ratio']).mark_rule(\n",
    "                color='grey', strokeWidth=2\n",
    "            ).encode(\n",
    "                x='min(peak_rt_start)'\n",
    "            )\n",
    "\n",
    "        # Add area window (end) of target (red verticle line)\n",
    "        unaligned_plot = unaligned_plot + alt.Chart(\n",
    "            df_concentration_peaks[df_concentration_peaks['signal_type'] == 'ratio']).mark_rule(\n",
    "                color='grey', strokeWidth=2\n",
    "            ).encode(\n",
    "                x='min(peak_rt_end)'\n",
    "            )    \n",
    "\n",
    "        # Ratio aligned + target rt\n",
    "        aligned_plot = alt.Chart(df_concentration_signal).mark_line().encode(\n",
    "            x='rt', y='ratio_aligned', color='sample'\n",
    "        ).properties(\n",
    "            width=plot_width, height=plot_height, \n",
    "            title=f\"ratio aligned ({concentration}) {t['name']}\"\n",
    "        )\n",
    "\n",
    "        # Add rt of target (red verticle line)\n",
    "        aligned_plot = aligned_plot + alt.Chart(\n",
    "            df_concentration_peaks[df_concentration_peaks['signal_type'] == 'ratio_aligned']).mark_rule(\n",
    "                color='red', strokeWidth=2\n",
    "            ).encode(\n",
    "                alt.X('mean(peak_rt_apex)',\n",
    "                  title='rt')        \n",
    "            )\n",
    "\n",
    "        # Add area window (start) of target (red verticle line)\n",
    "        aligned_plot = aligned_plot + alt.Chart(\n",
    "            df_concentration_peaks[df_concentration_peaks['signal_type'] == 'ratio_aligned']).mark_rule(\n",
    "                color='grey', strokeWidth=2\n",
    "            ).encode(\n",
    "                x='min(peak_rt_start)'\n",
    "            )\n",
    "\n",
    "        # Add area window (end) of target (red verticle line)\n",
    "        aligned_plot = aligned_plot + alt.Chart(\n",
    "            df_concentration_peaks[df_concentration_peaks['signal_type'] == 'ratio_aligned']).mark_rule(\n",
    "                color='grey', strokeWidth=2\n",
    "            ).encode(\n",
    "                x='min(peak_rt_end)'\n",
    "            )    \n",
    "\n",
    "        plots = alt.vconcat(plots, (intensity_plot | unaligned_plot | aligned_plot))\n",
    "                \n",
    "    # Display the plots        \n",
    "    plots.display()    \n",
    "\n",
    "    # Uncomment to save to disk\n",
    "    # plots.save(f\"plots/{t['name']}.png\", scale_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99091002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variation in area based on intensity and PCI_IS corrected ratio\n",
    "for tIdx, target in targets.iterrows():\n",
    "    \n",
    "    # Get target details\n",
    "    t = targets.loc[tIdx] \n",
    "\n",
    "    plots = []\n",
    "    for signal_type in ['intensity','ratio_aligned']:\n",
    "\n",
    "      # Filtered data source\n",
    "      peaks_filter = f\"target == {tIdx} and signal_type == '{signal_type}'\"    \n",
    "      source = df_peaks.query(peaks_filter)\n",
    "\n",
    "      error_points = alt.Chart(source).mark_point(filled=True).encode(\n",
    "        x=alt.X('area:Q', aggregate='mean', scale=alt.Scale(domain=[source['area'].min(),source['area'].max()])),\n",
    "        y=alt.Y('concentration:N', sort=alt.SortField('sample')),\n",
    "        color=alt.Color(\"concentration\", legend=None)\n",
    "      ).properties(width=350, height=70, title=f\"{t['name']}: mean area + error bars ({signal_type})\")    \n",
    "\n",
    "      # Mean area by concentration error bars\n",
    "      error_bars = alt.Chart(source).mark_errorbar(extent='ci').encode(\n",
    "        x=alt.X('area:Q', axis=alt.Axis(labels=False), scale=alt.Scale(domain=[source['area'].min(),source['area'].max()])),\n",
    "        y=alt.Y('concentration:N', sort=alt.SortField('sample')),\n",
    "        color=alt.Color(\"concentration\", legend=None)\n",
    "      ).properties(width=350, height=70)\n",
    "\n",
    "      # (error_points + error_bars).display()\n",
    "      plots.append((error_points + error_bars))\n",
    "\n",
    "    (plots[0] | plots[1]).display()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047701f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b52a1200dff0e61c4a219fa4dd745605d7e5a6676701478d00fa0ac5df10c706"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
